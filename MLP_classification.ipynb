{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96QFTeizJSTx"
   },
   "source": [
    "# Multiclass Text Tagging with Doc2Vec\n",
    "<span style=\"color:red\">Disclaimer: This notebook has been run on Google Colab!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ClR8xzqTC_V5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "w7yen95EVBVd",
    "outputId": "3b79e428-6cee-45b5-f8d7-1b12d3a31c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-2tdYcvVCLG"
   },
   "outputs": [],
   "source": [
    "data_path = \"/content/drive/My Drive/Cognitive Services/data/{}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ppmgT0DWhVW"
   },
   "outputs": [],
   "source": [
    "Xtr = np.load(data_path.format(\"Xtr\"), allow_pickle=True)\n",
    "Xte = np.load(data_path.format(\"Xte\"), allow_pickle=True)\n",
    "Ytr = np.load(data_path.format(\"Ytr\"), allow_pickle=True)\n",
    "Yte = np.load(data_path.format(\"Yte\"), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TekJeDsVY7dV"
   },
   "source": [
    "## MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDHbBGjiXpyR"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "bh6eQMaNZSkK",
    "outputId": "4e6e718f-42ee-4753-b419-8086f202840e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0622 18:28:17.910907 140035209521024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0622 18:28:17.925148 140035209521024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0622 18:28:17.944828 140035209521024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0622 18:28:17.955224 140035209521024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5000, activation='relu', input_dim=Xtr.shape[1]))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(Ytr.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "ksIWynBtZVPf",
    "outputId": "f9712887-a95a-4f78-e6cb-b8ebe9cfd8a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0622 18:28:22.972890 140035209521024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0622 18:28:22.979574 140035209521024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0622 18:28:22.985071 140035209521024 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17298
    },
    "colab_type": "code",
    "id": "SqPPTGSEbxa8",
    "outputId": "29312808-ec51-425d-b705-ce87a62404bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0557\n",
      "Epoch 2/500\n",
      "108160/108160 [==============================] - 1s 9us/step - loss: 0.0556\n",
      "Epoch 3/500\n",
      "108160/108160 [==============================] - 1s 9us/step - loss: 0.0556\n",
      "Epoch 4/500\n",
      "108160/108160 [==============================] - 1s 9us/step - loss: 0.0555\n",
      "Epoch 5/500\n",
      "108160/108160 [==============================] - 1s 9us/step - loss: 0.0554\n",
      "Epoch 6/500\n",
      "108160/108160 [==============================] - 1s 9us/step - loss: 0.0553\n",
      "Epoch 7/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0553\n",
      "Epoch 8/500\n",
      "108160/108160 [==============================] - 1s 9us/step - loss: 0.0552\n",
      "Epoch 9/500\n",
      "108160/108160 [==============================] - 1s 9us/step - loss: 0.0551\n",
      "Epoch 10/500\n",
      "108160/108160 [==============================] - 1s 9us/step - loss: 0.0551\n",
      "Epoch 11/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0550\n",
      "Epoch 12/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0549\n",
      "Epoch 13/500\n",
      "108160/108160 [==============================] - 1s 9us/step - loss: 0.0548\n",
      "Epoch 14/500\n",
      "108160/108160 [==============================] - 1s 9us/step - loss: 0.0548\n",
      "Epoch 15/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0547\n",
      "Epoch 16/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0546\n",
      "Epoch 17/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0545\n",
      "Epoch 18/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0544\n",
      "Epoch 19/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0544\n",
      "Epoch 20/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0543\n",
      "Epoch 21/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0542\n",
      "Epoch 22/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0541\n",
      "Epoch 23/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0541\n",
      "Epoch 24/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0540\n",
      "Epoch 25/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0539\n",
      "Epoch 26/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0538\n",
      "Epoch 27/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0537\n",
      "Epoch 28/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0536\n",
      "Epoch 29/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0536\n",
      "Epoch 30/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0535\n",
      "Epoch 31/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0534\n",
      "Epoch 32/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0533\n",
      "Epoch 33/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0532\n",
      "Epoch 34/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0531\n",
      "Epoch 35/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0530\n",
      "Epoch 36/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0529\n",
      "Epoch 37/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0529\n",
      "Epoch 38/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0528\n",
      "Epoch 39/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0527\n",
      "Epoch 40/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0526\n",
      "Epoch 41/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0525\n",
      "Epoch 42/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0524\n",
      "Epoch 43/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0523\n",
      "Epoch 44/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0522\n",
      "Epoch 45/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0521\n",
      "Epoch 46/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0520\n",
      "Epoch 47/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0519\n",
      "Epoch 48/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0518\n",
      "Epoch 49/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0517\n",
      "Epoch 50/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0516\n",
      "Epoch 51/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0515\n",
      "Epoch 52/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0514\n",
      "Epoch 53/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0513\n",
      "Epoch 54/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0512\n",
      "Epoch 55/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0512\n",
      "Epoch 56/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0510\n",
      "Epoch 57/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0509\n",
      "Epoch 58/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0508\n",
      "Epoch 59/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0507\n",
      "Epoch 60/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0506\n",
      "Epoch 61/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0505\n",
      "Epoch 62/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0504\n",
      "Epoch 63/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0503\n",
      "Epoch 64/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0502\n",
      "Epoch 65/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0501\n",
      "Epoch 66/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0500\n",
      "Epoch 67/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0499\n",
      "Epoch 68/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0498\n",
      "Epoch 69/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0497\n",
      "Epoch 70/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0496\n",
      "Epoch 71/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0495\n",
      "Epoch 72/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0494\n",
      "Epoch 73/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0493\n",
      "Epoch 74/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0492\n",
      "Epoch 75/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0491\n",
      "Epoch 76/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0490\n",
      "Epoch 77/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0489\n",
      "Epoch 78/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0487\n",
      "Epoch 79/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0486\n",
      "Epoch 80/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0485\n",
      "Epoch 81/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0484\n",
      "Epoch 82/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0483\n",
      "Epoch 83/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0482\n",
      "Epoch 84/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0481\n",
      "Epoch 85/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0480\n",
      "Epoch 86/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0479\n",
      "Epoch 87/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0478\n",
      "Epoch 88/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0477\n",
      "Epoch 89/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0476\n",
      "Epoch 90/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0475\n",
      "Epoch 91/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0473\n",
      "Epoch 92/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0472\n",
      "Epoch 93/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0471\n",
      "Epoch 94/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0470\n",
      "Epoch 95/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0469\n",
      "Epoch 96/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0468\n",
      "Epoch 97/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0467\n",
      "Epoch 98/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0466\n",
      "Epoch 99/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0465\n",
      "Epoch 100/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0464\n",
      "Epoch 101/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0463\n",
      "Epoch 102/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0462\n",
      "Epoch 103/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0461\n",
      "Epoch 104/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0460\n",
      "Epoch 105/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0459\n",
      "Epoch 106/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0458\n",
      "Epoch 107/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0457\n",
      "Epoch 108/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0456\n",
      "Epoch 109/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0455\n",
      "Epoch 110/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0454\n",
      "Epoch 111/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0453\n",
      "Epoch 112/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0452\n",
      "Epoch 113/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0451\n",
      "Epoch 114/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0450\n",
      "Epoch 115/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0449\n",
      "Epoch 116/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0448\n",
      "Epoch 117/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0447\n",
      "Epoch 118/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0446\n",
      "Epoch 119/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0445\n",
      "Epoch 120/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0444\n",
      "Epoch 121/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0443\n",
      "Epoch 122/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0442\n",
      "Epoch 123/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0441\n",
      "Epoch 124/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0440\n",
      "Epoch 125/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0440\n",
      "Epoch 126/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0439\n",
      "Epoch 127/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0438\n",
      "Epoch 128/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0437\n",
      "Epoch 129/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0436\n",
      "Epoch 130/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0435\n",
      "Epoch 131/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0434\n",
      "Epoch 132/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0433\n",
      "Epoch 133/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0433\n",
      "Epoch 134/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0432\n",
      "Epoch 135/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0431\n",
      "Epoch 136/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0430\n",
      "Epoch 137/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0429\n",
      "Epoch 138/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0429\n",
      "Epoch 139/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0428\n",
      "Epoch 140/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0427\n",
      "Epoch 141/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0426\n",
      "Epoch 142/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0425\n",
      "Epoch 143/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0425\n",
      "Epoch 144/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0424\n",
      "Epoch 145/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0423\n",
      "Epoch 146/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0422\n",
      "Epoch 147/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0422\n",
      "Epoch 148/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0421\n",
      "Epoch 149/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0420\n",
      "Epoch 150/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0420\n",
      "Epoch 151/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0419\n",
      "Epoch 152/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0418\n",
      "Epoch 153/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0417\n",
      "Epoch 154/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0417\n",
      "Epoch 155/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0416\n",
      "Epoch 156/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0415\n",
      "Epoch 157/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0415\n",
      "Epoch 158/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0414\n",
      "Epoch 159/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0414\n",
      "Epoch 160/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0413\n",
      "Epoch 161/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0412\n",
      "Epoch 162/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0412\n",
      "Epoch 163/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0411\n",
      "Epoch 164/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0410\n",
      "Epoch 165/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0410\n",
      "Epoch 166/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0409\n",
      "Epoch 167/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0409\n",
      "Epoch 168/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0408\n",
      "Epoch 169/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0407\n",
      "Epoch 170/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0407\n",
      "Epoch 171/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0406\n",
      "Epoch 172/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0406\n",
      "Epoch 173/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0405\n",
      "Epoch 174/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0405\n",
      "Epoch 175/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0404\n",
      "Epoch 176/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0404\n",
      "Epoch 177/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0403\n",
      "Epoch 178/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0402\n",
      "Epoch 179/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0402\n",
      "Epoch 180/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0402\n",
      "Epoch 181/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0401\n",
      "Epoch 182/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0401\n",
      "Epoch 183/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0400\n",
      "Epoch 184/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0399\n",
      "Epoch 185/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0399\n",
      "Epoch 186/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0399\n",
      "Epoch 187/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0398\n",
      "Epoch 188/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0398\n",
      "Epoch 189/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0397\n",
      "Epoch 190/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0397\n",
      "Epoch 191/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0396\n",
      "Epoch 192/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0396\n",
      "Epoch 193/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0395\n",
      "Epoch 194/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0395\n",
      "Epoch 195/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0395\n",
      "Epoch 196/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0394\n",
      "Epoch 197/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0394\n",
      "Epoch 198/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0393\n",
      "Epoch 199/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0393\n",
      "Epoch 200/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0393\n",
      "Epoch 201/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0392\n",
      "Epoch 202/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0392\n",
      "Epoch 203/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0392\n",
      "Epoch 204/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0391\n",
      "Epoch 205/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0391\n",
      "Epoch 206/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0391\n",
      "Epoch 207/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0390\n",
      "Epoch 208/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0390\n",
      "Epoch 209/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0389\n",
      "Epoch 210/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0389\n",
      "Epoch 211/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0389\n",
      "Epoch 212/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0388\n",
      "Epoch 213/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0388\n",
      "Epoch 214/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0388\n",
      "Epoch 215/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0387\n",
      "Epoch 216/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0387\n",
      "Epoch 217/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0387\n",
      "Epoch 218/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0386\n",
      "Epoch 219/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0386\n",
      "Epoch 220/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0386\n",
      "Epoch 221/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0385\n",
      "Epoch 222/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0385\n",
      "Epoch 223/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0385\n",
      "Epoch 224/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0385\n",
      "Epoch 225/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0384\n",
      "Epoch 226/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0384\n",
      "Epoch 227/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0384\n",
      "Epoch 228/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0384\n",
      "Epoch 229/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0383\n",
      "Epoch 230/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0383\n",
      "Epoch 231/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0383\n",
      "Epoch 232/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0383\n",
      "Epoch 233/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0382\n",
      "Epoch 234/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0382\n",
      "Epoch 235/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0381\n",
      "Epoch 236/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0381\n",
      "Epoch 237/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0381\n",
      "Epoch 238/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0381\n",
      "Epoch 239/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0381\n",
      "Epoch 240/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0380\n",
      "Epoch 241/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0380\n",
      "Epoch 242/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0380\n",
      "Epoch 243/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0380\n",
      "Epoch 244/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0380\n",
      "Epoch 245/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0379\n",
      "Epoch 246/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0379\n",
      "Epoch 247/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0379\n",
      "Epoch 248/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0378\n",
      "Epoch 249/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0378\n",
      "Epoch 250/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0378\n",
      "Epoch 251/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0378\n",
      "Epoch 252/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0378\n",
      "Epoch 253/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0377\n",
      "Epoch 254/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0377\n",
      "Epoch 255/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0377\n",
      "Epoch 256/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0377\n",
      "Epoch 257/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0377\n",
      "Epoch 258/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0377\n",
      "Epoch 259/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0376\n",
      "Epoch 260/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0376\n",
      "Epoch 261/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0376\n",
      "Epoch 262/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0376\n",
      "Epoch 263/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0375\n",
      "Epoch 264/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0375\n",
      "Epoch 265/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0375\n",
      "Epoch 266/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0375\n",
      "Epoch 267/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0375\n",
      "Epoch 268/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0375\n",
      "Epoch 269/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0374\n",
      "Epoch 270/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0374\n",
      "Epoch 271/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0374\n",
      "Epoch 272/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0374\n",
      "Epoch 273/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0374\n",
      "Epoch 274/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0374\n",
      "Epoch 275/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0374\n",
      "Epoch 276/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0374\n",
      "Epoch 277/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0373\n",
      "Epoch 278/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0373\n",
      "Epoch 279/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0373\n",
      "Epoch 280/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0373\n",
      "Epoch 281/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0373\n",
      "Epoch 282/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0372\n",
      "Epoch 283/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0372\n",
      "Epoch 284/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0372\n",
      "Epoch 285/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0372\n",
      "Epoch 286/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0372\n",
      "Epoch 287/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0372\n",
      "Epoch 288/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0371\n",
      "Epoch 289/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0371\n",
      "Epoch 290/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0371\n",
      "Epoch 291/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0371\n",
      "Epoch 292/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0371\n",
      "Epoch 293/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0371\n",
      "Epoch 294/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0370\n",
      "Epoch 295/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0371\n",
      "Epoch 296/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0371\n",
      "Epoch 297/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0370\n",
      "Epoch 298/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0370\n",
      "Epoch 299/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0370\n",
      "Epoch 300/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0370\n",
      "Epoch 301/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0370\n",
      "Epoch 302/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0370\n",
      "Epoch 303/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0370\n",
      "Epoch 304/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0369\n",
      "Epoch 305/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0369\n",
      "Epoch 306/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0369\n",
      "Epoch 307/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0369\n",
      "Epoch 308/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0369\n",
      "Epoch 309/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0369\n",
      "Epoch 310/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0369\n",
      "Epoch 311/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0369\n",
      "Epoch 312/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0369\n",
      "Epoch 313/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 314/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 315/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 316/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 317/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 318/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 319/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 320/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 321/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0367\n",
      "Epoch 322/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 323/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0367\n",
      "Epoch 324/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0368\n",
      "Epoch 325/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0367\n",
      "Epoch 326/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0367\n",
      "Epoch 327/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0367\n",
      "Epoch 328/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0367\n",
      "Epoch 329/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0367\n",
      "Epoch 330/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0367\n",
      "Epoch 331/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0367\n",
      "Epoch 332/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 333/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0367\n",
      "Epoch 334/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 335/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 336/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 337/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 338/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 339/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 340/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 341/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 342/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 343/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0366\n",
      "Epoch 344/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 345/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 346/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 347/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 348/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 349/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 350/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 351/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 352/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 353/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 354/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 355/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0365\n",
      "Epoch 356/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 357/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 358/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 359/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 360/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 361/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 362/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 363/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 364/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 365/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 366/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 367/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 368/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 369/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 370/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 371/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0364\n",
      "Epoch 372/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 373/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 374/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 375/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 376/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 377/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 378/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 379/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 380/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 381/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 382/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 383/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 384/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 385/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 386/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0363\n",
      "Epoch 387/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 388/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 389/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 390/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 391/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 392/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 393/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 394/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 395/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 396/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 397/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 398/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 399/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 400/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 401/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0362\n",
      "Epoch 402/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 403/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 404/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 405/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 406/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 407/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 408/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 409/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 410/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 411/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 412/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 413/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 414/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 415/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 416/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 417/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 418/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0361\n",
      "Epoch 419/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 420/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 421/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 422/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 423/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 424/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 425/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 426/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 427/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 428/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 429/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 430/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 431/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 432/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 433/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 434/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 435/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0360\n",
      "Epoch 436/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 437/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 438/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 439/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 440/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 441/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 442/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 443/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 444/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 445/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 446/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 447/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 448/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 449/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 450/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 451/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 452/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 453/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 454/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 455/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 456/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 457/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 458/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0359\n",
      "Epoch 459/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 460/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 461/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 462/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 463/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 464/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 465/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 466/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 467/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 468/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 469/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 470/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 471/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 472/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 473/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 474/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 475/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 476/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 477/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 478/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 479/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 480/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 481/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 482/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 483/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 484/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 485/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0358\n",
      "Epoch 486/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0357\n",
      "Epoch 487/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0357\n",
      "Epoch 488/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0357\n",
      "Epoch 489/500\n",
      "108160/108160 [==============================] - 1s 10us/step - loss: 0.0357\n",
      "Epoch 490/500\n",
      " 32000/108160 [=======>......................] - ETA: 0s - loss: 0.0358"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0055e087f48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(Xtr, Ytr, epochs=500, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eGjP97WXbyFJ",
    "outputId": "d15c5415-c179-413a-f820-a4079c12757a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31, 58, 39, ...,  1, 48,  9])"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sf58SNQue0MZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5btLyFGvfIUn"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.argmax(Yte, axis=1), model.predict_classes(Xte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "GbNy_k6HfOBb",
    "outputId": "f5e85a11-7fcc-46d0-88cb-250bc0be974d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ba5f20f28>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wGxSgI1JaJxqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ezqDv935yj1_",
    "outputId": "617055c9-fee1-4f9c-a157-8e29e725cd1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3269230769230769"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(Yte, axis=1), model.predict_classes(Xte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8REsNnjQyn-w",
    "outputId": "57627765-038c-41d4-b85a-b59a9924a7d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32736501008419105"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(np.argmax(Yte, axis=1), model.predict_classes(Xte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pFXN-CmszCCt",
    "outputId": "95d42a4c-0343-4911-d78b-4ba4517408ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30561229972648607"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.argmax(Yte, axis=1), model.predict_classes(Xte), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1c-NbmvZzqh-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Facebook_kaggle_Doc2Vec",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
